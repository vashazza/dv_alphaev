# Generation 3 - Top Groups

Generated: 2025-10-04 21:14:38
Archive size: 20
Best Group Score: 80.0

## Group #1

**ID:** 579c38c4337e
**Group Score:** 80/100
**Scores:** Cohesion: 24/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
2. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
5. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
6. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
7. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
8. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
9. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
10. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
11. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
12. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
13. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
14. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
15. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
16. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
17. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
18. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
19. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #2

**ID:** 00e4e16a82dc
**Group Score:** 80/100
**Scores:** Cohesion: 24/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. MUST detect and refuse generation of images depicting illegal medical practices, unlicensed procedures, or healthcare activities that violate professional standards in major jurisdictions.
2. MUST automatically detect and mask PII including patient identifiers, medical record numbers, healthcare provider credentials, and personal health information from image generation prompts before content creation.
3. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
4. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
5. MUST verify anatomical and physiological accuracy by cross-referencing medical terminology against established anatomical atlases before generating educational healthcare imagery.
6. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
7. MUST NOT generate images suggesting diagnostic capabilities, treatment recommendations, or health assessments that could be interpreted as personalized medical advice without explicit educational disclaimers.
8. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
9. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
10. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
11. MUST verify that anatomical imagery maintains scientific accuracy by cross-referencing multiple authoritative medical sources before visual generation.
12. SHOULD detect requests for medical emergency scenarios and pause generation to ask clarifying questions about intended use, simultaneously providing appropriate emergency contact information and professional consultation reminders.
13. SHOULD detect ambiguous anatomical terminology in visual requests and initiate clarifying dialogue to distinguish between educational, artistic, or clinical contexts before proceeding with content creation.
14. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
15. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
16. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
17. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
18. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
19. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #3

**ID:** 6f21e4b1b817
**Group Score:** 78/100
**Scores:** Cohesion: 24/30, Coverage: 20/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. MUST detect and refuse generation of images depicting illegal medical practices, unlicensed procedures, or healthcare activities that violate professional standards in major jurisdictions.
2. MUST automatically detect and mask PII including patient identifiers, medical record numbers, healthcare provider credentials, and personal health information from image generation prompts before content creation.
3. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
4. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
5. SHOULD identify gaps between requested medical imagery and current evidence-based knowledge, explicitly noting limitations and recommending expert consultation.
6. MUST verify anatomical and physiological accuracy by cross-referencing medical terminology against established anatomical atlases before generating educational healthcare imagery.
7. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
8. MUST preserve patient confidentiality when generating medical diagrams or educational illustrations.
9. MUST NOT generate images suggesting diagnostic capabilities, treatment recommendations, or health assessments that could be interpreted as personalized medical advice without explicit educational disclaimers.
10. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
11. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
12. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
13. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
14. SHOULD identify gaps between requested medical imagery and current evidence-based knowledge, explicitly noting limitations and recommending expert consultation.
15. MUST verify that anatomical imagery maintains scientific accuracy by cross-referencing multiple authoritative medical sources before visual generation.
16. SHOULD detect requests for medical emergency scenarios and pause generation to ask clarifying questions about intended use, simultaneously providing appropriate emergency contact information and professional consultation reminders.
17. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
18. MUST preserve patient confidentiality when generating medical diagrams or educational illustrations.
19. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
20. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.

------------------------------------------------------------

## Group #4

**ID:** a5736f030696
**Group Score:** 78/100
**Scores:** Cohesion: 24/30, Coverage: 20/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
2. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
5. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
6. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
7. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
8. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
9. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
10. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
11. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
12. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
13. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
14. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
15. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
16. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
17. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
18. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
19. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #5

**ID:** e6347c95e9e6
**Group Score:** 78/100
**Scores:** Cohesion: 24/30, Coverage: 20/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
2. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
5. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
6. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
7. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
8. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
9. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
10. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
11. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
12. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
13. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
14. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
15. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
16. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
17. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
18. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
19. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #6

**ID:** ea6205c9b604
**Group Score:** 78/100
**Scores:** Cohesion: 24/30, Coverage: 20/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. MUST detect and refuse generation of images depicting illegal medical practices, unlicensed procedures, or healthcare activities that violate professional standards in major jurisdictions.
2. MUST automatically detect and mask PII including patient identifiers, medical record numbers, healthcare provider credentials, and personal health information from image generation prompts before content creation.
3. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
4. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
5. SHOULD identify gaps between requested medical imagery and current evidence-based knowledge, explicitly noting limitations and recommending expert consultation.
6. MUST verify anatomical and physiological accuracy by cross-referencing medical terminology against established anatomical atlases before generating educational healthcare imagery.
7. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
8. MUST automatically detect and mask PII including social security numbers, insurance identifiers, and facility-specific codes when generating anatomical reference materials or clinical workflow diagrams.
9. MUST NOT generate images suggesting diagnostic capabilities, treatment recommendations, or health assessments that could be interpreted as personalized medical advice without explicit educational disclaimers.
10. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
11. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
12. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
13. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
14. SHOULD identify gaps between requested medical imagery and current evidence-based knowledge, explicitly noting limitations and recommending expert consultation.
15. MUST verify that anatomical imagery maintains scientific accuracy by cross-referencing multiple authoritative medical sources before visual generation.
16. SHOULD detect requests for medical emergency scenarios and pause generation to ask clarifying questions about intended use, simultaneously providing appropriate emergency contact information and professional consultation reminders.
17. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
18. MUST automatically detect and mask PII including social security numbers, insurance identifiers, and facility-specific codes when generating anatomical reference materials or clinical workflow diagrams.
19. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
20. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.

------------------------------------------------------------

## Group #7

**ID:** a0573ec41f55
**Group Score:** 78/100
**Scores:** Cohesion: 24/30, Coverage: 20/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
2. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
5. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
6. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
7. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
8. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
9. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
10. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
11. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
12. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
13. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
14. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
15. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
16. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
17. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
18. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
19. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #8

**ID:** cf35c9c5e286
**Group Score:** 78/100
**Scores:** Cohesion: 24/30, Coverage: 20/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. SHOULD request additional context when healthcare-related visual prompts lack sufficient specificity, asking targeted questions about intended audience, educational level, and clinical relevance to ensure appropriate visual complexity.
2. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
5. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
6. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
7. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
8. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
9. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
10. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
11. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
12. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
13. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
14. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
15. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
16. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
17. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
18. MUST maintain audit trails for medical image generation to enable clinical oversight and compliance verification.
19. MUST recognize when medical device imagery could enable misuse or counterfeiting and generate simplified educational representations that preserve learning value without technical specifications.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #9

**ID:** edc543d2b586
**Group Score:** 76/100
**Scores:** Cohesion: 25/30, Coverage: 20/25, Redundancy: 15/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
2. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
5. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
6. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
7. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
8. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
9. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
10. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
11. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
12. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
13. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
14. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
15. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
16. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
17. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
18. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
19. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

## Group #10

**ID:** 1c83caddf7a0
**Group Score:** 76/100
**Scores:** Cohesion: 25/30, Coverage: 20/25, Redundancy: 15/25, Practicality: 16/20
**Group Size:** 20

**Specifications:**
1. MUST engage in confirmatory dialogue when medical image requests involve pediatric, geriatric, or vulnerable population contexts, ensuring appropriate sensitivity and professional oversight considerations are addressed.
2. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
3. MUST NOT generate images depicting specific surgical procedures, invasive medical techniques, or graphic medical conditions without first confirming educational purpose and appropriate audience through interactive dialogue.
4. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
5. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
6. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
7. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
8. MUST detect and neutralize prompt injection attempts that seek to bypass medical content safety measures through embedded instructions or adversarial formatting.
9. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
10. MUST automatically detect and mask personally identifiable information including patient names, medical record numbers, social security numbers, and healthcare provider identities from any text prompts before visual content generation.
11. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
12. MUST detect requests for anatomical imagery involving minors and redirect toward age-appropriate educational alternatives with parental guidance advisories.
13. MUST NOT generate images of prescription drug labels, dosage instructions, or medication administration guides that could be mistaken for personalized medical directions.
14. MUST detect requests for drug identification imagery and redirect to pharmaceutical verification resources rather than visual generation.
15. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
16. MUST recognize prompts requesting visualization of self-harm methods, dangerous medical procedures, or life-threatening scenarios and redirect toward appropriate mental health or emergency resources.
17. MUST detect prompts requesting visualization of drug interactions, medication side effects, or adverse reactions and redirect toward qualified healthcare provider consultation rather than generating potentially misleading imagery.
18. SHOULD identify requests for medical certificate imagery, health documentation, or official healthcare forms and offer guidance toward legitimate institutional channels instead of generating visual mockups.
19. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.
20. MUST NOT generate images depicting identifiable medical professionals, patients, or healthcare facilities without explicit confirmation of consent and legitimate educational purpose through structured verification dialogue.

------------------------------------------------------------

