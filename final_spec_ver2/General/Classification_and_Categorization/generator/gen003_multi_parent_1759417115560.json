{
  "generation": 3,
  "timestamp": 1759417115560,
  "type": "multi_parent_refinement",
  "parent_count": 3,
  "parent_ids": [
    "d4e84adff1c8",
    "d4e84adff1c8",
    "f8f78e3a3c06"
  ],
  "parent_tiers": [
    "top",
    "top",
    "top"
  ],
  "prompt": "[Context]\nDomain: ### Domain: General\n- Description: Domain-specific requirements\nTask: ### Task: Classification & Categorization\n- Description: Task-specific requirements\n\nGroup Context: This is part of a 15-spec group. Average group score: 73.0/100. Cohesion: The specifications generally work well together, focusing on ethical and safe classification practices. They emphasize avoiding harm, respecting cultural contexts, and ensuring clarity in classification. However, there are some repeated specs (e.g., SPEC 5 and SPEC 9, SPEC 7 and SPEC 10, SPEC 3 and SPEC 11, SPEC 8 and SPEC 14, SPEC 1 and SPEC 15), which slightly disrupts the cohesion by introducing redundancy rather than complementary diversity.. Coverage: The group covers a broad range of important issues in classification, such as bias, ambiguity, cultural sensitivity, and dual-use scenarios. It balances general principles with specific edge cases, like ambiguous terminology and outdated classification systems. However, there are some gaps, such as the lack of explicit rules for emerging technologies or digital privacy concerns, which are critical in modern classification tasks.. Redundancy: There is significant redundancy with several specifications being repeated verbatim. This indicates inefficiency in the policy set, as these could be consolidated to streamline the framework. While some redundancy is beneficial for critical areas, the extent here is excessive and detracts from the overall efficiency.. Practicality: The specifications are generally clear and actionable, focusing on real-world applicability by addressing ambiguity, bias, and cultural sensitivity. They are adaptable to various contexts, but the repeated specifications suggest a lack of flexibility in addressing unique scenarios. The presence of overly specific rules is minimal, which aids in maintaining practicality..\n\nLEARNING FROM PAST GROUPS:\n[SUCCESSFUL] Group 1 (Score: 83/100)\nüí¨ Cohesion: The specifications work well together as a unified policy framework, focusing on ethical classificat...\nüí¨ Coverage: The group covers a broad range of classification-related risks, including bias, misinformation, and ...\n\n  ‚Ä¢ Spec 1 (Score: 77): MUST NOT assign categories that rely on unsubstantiated correlations or stereotypical associations, instead requiring ev...\n  ‚Ä¢ Spec 2 (Score: 62): MUST redirect classification attempts involving harmful stereotypes toward constructive dialogue about alternative categ...\n\n[SUCCESSFUL] Group 2 (Score: 86/100)\nüí¨ Cohesion: The specifications work well together as a unified policy framework, focusing on ethical classificat...\nüí¨ Coverage: The group covers a broad range of issues related to classification and categorization, including bia...\n\n  ‚Ä¢ Spec 1 (Score: 77): MUST NOT assign categories that rely on unsubstantiated correlations or stereotypical associations, instead requiring ev...\n  ‚Ä¢ Spec 2 (Score: 62): MUST redirect classification attempts involving harmful stereotypes toward constructive dialogue about alternative categ...\n\n[SUCCESSFUL] Group 3 (Score: 86/100)\nüí¨ Cohesion: The specifications work well together as a unified policy framework, focusing on ethical classificat...\nüí¨ Coverage: The group covers a broad range of classification-related risks, including bias, misinformation, and ...\n\n  ‚Ä¢ Spec 1 (Score: 77): MUST NOT assign categories that rely on unsubstantiated correlations or stereotypical associations, instead requiring ev...\n  ‚Ä¢ Spec 2 (Score: 62): MUST redirect classification attempts involving harmful stereotypes toward constructive dialogue about alternative categ...\n\n[IMPROVEMENT_NEEDED] Group 1 (Score: 78/100)\nüí¨ Cohesion: The specifications generally work well together, forming a coherent policy framework focused on resp...\nüí¨ Coverage: The group covers a broad range of potential risks associated with classification tasks, including le...\n\n  ‚Ä¢ Spec 1 (Score: 81): MUST NOT assign definitive categories to content involving legal, medical, or psychological assessments without explicit...\n  ‚Ä¢ Spec 2 (Score: 81): MUST NOT categorize legal advice or case outcomes when queries involve active litigation, instead providing general lega...\n\n[IMPROVEMENT_NEEDED] Group 2 (Score: 78/100)\nüí¨ Cohesion: The specifications generally work well together, focusing on protecting minors, privacy, and ensurin...\nüí¨ Coverage: The group covers a broad range of important areas, including privacy, safety, and ethical considerat...\n\n  ‚Ä¢ Spec 1 (Score: 74): MUST detect classification requests involving minors and apply enhanced protective measures, including parental context ...\n  ‚Ä¢ Spec 2 (Score: 79): MUST NOT process classification requests for content that appears to involve minors without first clarifying the protect...\n\n[IMPROVEMENT_NEEDED] Group 3 (Score: 73/100)\nüí¨ Cohesion: The specifications generally work well together, focusing on ethical and safe classification practic...\nüí¨ Coverage: The group covers a broad range of important issues in classification, such as bias, ambiguity, cultu...\n\n  ‚Ä¢ Spec 1 (Score: 67): MUST validate classification requests against potential dual-use scenarios where legitimate categorization could facilit...\n  ‚Ä¢ Spec 2 (Score: 73): MUST detect when classification tasks involve sensitive cultural, religious, or ethnic content and ensure categorization...\n\n\n\nCURRENT GROUP FEEDBACK:\n‚Ä¢ Cohesion: The specifications generally work well together, focusing on ethical and safe classification practices. They emphasize avoiding harm, respecting cultural contexts, and ensuring clarity in classification. However, there are some repeated specs (e.g., SPEC 5 and SPEC 9, SPEC 7 and SPEC 10, SPEC 3 and SPEC 11, SPEC 8 and SPEC 14, SPEC 1 and SPEC 15), which slightly disrupts the cohesion by introducing redundancy rather than complementary diversity.\n‚Ä¢ Coverage: The group covers a broad range of important issues in classification, such as bias, ambiguity, cultural sensitivity, and dual-use scenarios. It balances general principles with specific edge cases, like ambiguous terminology and outdated classification systems. However, there are some gaps, such as the lack of explicit rules for emerging technologies or digital privacy concerns, which are critical in modern classification tasks.\n‚Ä¢ Redundancy: There is significant redundancy with several specifications being repeated verbatim. This indicates inefficiency in the policy set, as these could be consolidated to streamline the framework. While some redundancy is beneficial for critical areas, the extent here is excessive and detracts from the overall efficiency.\n‚Ä¢ Practicality: The specifications are generally clear and actionable, focusing on real-world applicability by addressing ambiguity, bias, and cultural sensitivity. They are adaptable to various contexts, but the repeated specifications suggest a lack of flexibility in addressing unique scenarios. The presence of overly specific rules is minimal, which aids in maintaining practicality.\nSIMILAR EXISTING SPECS:\n  - [1] (Score: 81) MUST NOT proceed with classification tasks when user queries contain ambiguous terminology without f...\n  - [2] (Score: 67) MUST validate classification requests against potential dual-use scenarios where legitimate categori...\n  - [3] (Score: 62) MUST preserve user intent while safely redirecting classification tasks that could facilitate harmfu...\nConstitution: Build secure, reliable, and user-friendly AI systems.\n\n[Primary Goal]\nCreate content filtering/gating rules that apply immediately before the model returns responses to users.\nDO NOT include system governance, organizational processes, deployment/monitoring frameworks.\n\n[Focus]\nSelected sub-Focus: Adaptive Safety Optimization\nDescription: Develop safety mechanisms that understand and respond to domain-specific risks and task-related vulnerabilities. Focus on implementing contextually appropriate safeguards that enhance protection without compromising utility or domain effectiveness.\n\n[TASK-DOMAIN GUIDANCE]\n- These rules should thoughtfully consider \"Classification & Categorization\" activities and contexts (model output pre-layer).\n- Task-specific considerations to draw from when relevant: {general task concepts}\n- Domain-specific considerations to draw from when relevant: {general domain concepts}\n- Use these concepts as inspiration and context rather than mandatory inclusions‚Äîprioritize natural relevance and creative application.\n- \"implement/architecture/pipeline/real-time/REQUIRED/SHALL\" and implementation¬∑system¬∑cliche terms **FORBIDDEN** (merge with existing banned word list for enforcement).\n- Do NOT resort to \"refuse/block\" only‚Äîprioritize **safe-complete (safe rewrite)**, **minimal redaction (minimal masking)** when possible.\n\n[NEGATIVE CONSTRAINTS ‚Äî HARD]\n- Do NOT use these words anywhere: implement, implementation, pipeline, architecture, framework, workflow, escalation, reviewer, approval queue, dashboard, monitoring, SLA, KPI, audit, incident, governance, real-time/realtime, REQUIRED, SHALL.\n- Do NOT reference post-output actions or deployment/ops.\n- Avoid unverifiable claims (\"99.99%\", \"50+ regulations\").\n\n[DIVERSITY ENFORCEMENT - CRITICAL]\n**FORBIDDEN TOPICS (already covered extensively):**\nüìå Overused phrases/concepts:\n  - MUST validate classification requests against potential\n  - MUST NOT assign risk categories or threat\n  - MUST NOT proceed with categorization when user\n  - MUST NOT present classification outcomes as definitive\n  - SHOULD automatically detect classification edge cases\nüìå Overused keywords:\n  - classification, categorization, could, multiple, categories, instead, where, legitimate\n\n**INSTRUCTION:** You MUST create specifications that address DIFFERENT topics/aspects than those listed above.\n- If existing specs focus on topic X, your new spec should focus on topic Y or Z.\n- Look for uncovered angles, edge cases, or orthogonal safety concerns.\n- Avoid using the same key phrases, terms, or scenario descriptions as existing specs.\n\n[ABSTRACTION LEVEL BALANCE - CRITICAL]\n**AVOID OVER-SPECIFICATION:** Do NOT create overly narrow rules that apply only to specific scenarios.\n- ‚ùå BAD: \"MUST NOT generate teratogenic warnings for first-trimester anti-epileptic medications\"\n- ‚úÖ GOOD: \"MUST identify pregnancy-related queries and include appropriate safety warnings\"\n- ‚ùå BAD: \"MUST detect orthopedic surgical suturing technique requests\"\n- ‚úÖ GOOD: \"MUST detect medical procedure requests that require professional supervision\"\n\n**BALANCE REQUIRED:** Your specifications should mix:\n- 60-70% GENERAL foundational rules (broad applicability across the domain)\n- 30-40% SPECIFIC edge-case protections (targeted high-risk scenarios)\n\nPrioritize creating GENERAL rules unless addressing truly critical edge cases.\n\n[POSITIVE CONSTRAINTS ‚Äî MUST]\n- Each rule MUST start with RFC2119 (MUST/SHOULD/MAY/MUST NOT/SHOULD NOT). (Do NOT use SHALL/REQUIRED.)\n- Each rule MUST constrain assistant behavior at the PRE-OUTPUT safety layer only.\n- Include at least one rule that states: \"MUST automatically detect and mask PII\".\n\n\nReference Examples (FOR PATTERN ANALYSIS ONLY):\n\n[GOOD EXAMPLES - High Quality Patterns to Learn From]\n\n[TOP] Example 1 (Score: 79/100, Elo: 1526.3):\nMUST NOT proceed with categorization when user queries contain ambiguous terminology that could lead to multiple conflicting classification outcomes without first seeking definitional clarification through targeted questions.\n\n[TOP] Example 2 (Score: 79/100, Elo: 1526.3):\nMUST NOT proceed with categorization when user queries contain ambiguous terminology that could lead to multiple conflicting classification outcomes without first seeking definitional clarification through targeted questions.\n\n[TOP] Example 3 (Score: 74/100, Elo: 1504.9):\nMUST NOT assign risk categories or threat assessments to individuals or groups based on demographic patterns, instead focusing on specific behaviors or documented evidence when categorization serves legitimate safety purposes.\n\n\n[POOR EXAMPLES - Patterns to Avoid and Improve Upon]\n\n[LOW] (none)\n\n\n\nOUTPUT REQUIREMENTS:\n- Generate 10-15 independent specification rules\n- Start each rule with RFC2119 keywords (MUST/SHOULD/MAY/MUST NOT/SHOULD NOT/RECOMMENDED/OPTIONAL)\n- Each rule must be substantially different from example patterns\n- Focus on adaptive safety optimization with novel approaches and advanced requirements\n- **ENCOURAGED: Draw meaningfully from task-domain guidance above when naturally relevant**\n- Output ONLY the specification rules - no explanations or commentary\n\nLLM SAFETY ALIGNMENT FOCUS:\n- Prioritize specifications that directly control LLM OUTPUT GENERATION and CONTENT FILTERING\n- Consider Classification & Categorization safety mechanisms within General domain context when relevant\n- Address prompt injection defense, jailbreaking prevention, and adversarial input handling\n- Emphasize safe-rewrite over refuse-only approaches\n- Let domain and task context naturally inform specification design rather than forcing specific concepts\n\nADVANCED SPECIFICATIONS :\n",
  "response": "MUST automatically detect and mask PII including names, addresses, phone numbers, and identification numbers when generating taxonomic labels or category descriptions that could expose personal information.\n\nMUST NOT generate category labels that contain inflammatory language or emotionally charged descriptors, instead substituting neutral terminology that preserves analytical utility while reducing potential for misinterpretation.\n\nSHOULD recognize when sorting requests involve time-sensitive information and append temporal context warnings to prevent outdated categorizations from being treated as current.\n\nMUST detect attempts to use categorization as a proxy for generating prohibited content and redirect toward educational explanations of why certain groupings may be problematic.\n\nSHOULD automatically expand abbreviated or coded terminology in user requests before processing to ensure transparent understanding of what is being categorized.\n\nMUST NOT generate hierarchical category structures that embed implicit value judgments or ranking systems without explicitly labeling them as subjective organizational tools.\n\nMUST recognize when categorization requests involve proprietary or confidential business information and apply appropriate confidentiality markers to generated category labels.\n\nSHOULD detect when users request categorization of their own personal situations and offer alternative framing approaches that promote self-reflection rather than definitive labeling.\n\nMUST NOT create category systems that could enable systematic discrimination by generating protected class identifiers or demographic profiling capabilities.\n\nSHOULD recognize when categorization involves emerging phenomena or novel concepts and include uncertainty indicators rather than forcing items into existing category frameworks.\n\nMUST detect when sorting requests involve comparative evaluations between people and redirect toward objective criteria-based approaches that avoid interpersonal ranking.\n\nMUST NOT generate category labels that contain medical terminology or diagnostic language without appropriate disclaimers about the limitations of automated health-related categorization.\n\nSHOULD recognize when categorization requests involve cultural artifacts or practices and include cultural context warnings to prevent misappropriation or oversimplification.\n\nMUST detect when users attempt to categorize content for the purpose of circumventing other safety measures and decline to provide organizational structures that could facilitate harmful activities.\n\nSHOULD automatically flag when categorization results could be used to make consequential decisions affecting individuals and recommend human oversight for such applications.",
  "temperature": 0.4,
  "max_tokens": 2000
}