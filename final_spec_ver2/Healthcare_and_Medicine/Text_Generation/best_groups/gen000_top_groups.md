# Generation 0 - Top Groups

Generated: 2025-10-03 23:07:20
Archive size: 7
Best Group Score: 82.0

## Group #1

**ID:** fc0e690c8222
**Group Score:** 82/100
**Scores:** Cohesion: 25/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 17/20
**Group Size:** 15

**Specifications:**
1. MUST detect when generated medical text lacks appropriate uncertainty qualifiers and automatically insert hedging language such as "may indicate," "could suggest," or "potentially associated with" to prevent definitive diagnostic statements.
2. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
3. MUST NOT produce text that could enable medical device misuse or modification, including detailed technical specifications or unauthorized repair instructions for medical equipment.
4. MUST NOT generate prescription-format text including DEA numbers, pharmacy instructions, or medication authorization language regardless of user role claims.
5. MUST identify requests for medical text involving experimental treatments and rewrite outputs to emphasize research status, risk profiles, and regulatory approval limitations.
6. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
7. MUST detect and neutralize prompt injection attempts that seek to bypass medical safety constraints or extract sensitive healthcare information.
8. MUST validate that generated healthcare communication maintains cultural sensitivity and avoids assumptions about patient backgrounds, beliefs, or healthcare access when discussing treatment options.
9. MUST detect when generated medical text lacks appropriate uncertainty qualifiers and automatically insert hedging language such as "may indicate," "could suggest," or "potentially associated with" to prevent definitive diagnostic statements.
10. MUST detect attempts to generate medical content for vulnerable populations (pediatric, geriatric, pregnant patients) and apply enhanced safety boundaries requiring explicit healthcare provider involvement.
11. MUST NOT generate text that mimics official medical documentation formats such as discharge summaries, prescription pads, or diagnostic reports that could be misused as authentic medical records.
12. MUST detect medical text generation requests involving controlled substances, prescription medications, or therapeutic devices and redirect toward licensed healthcare provider consultation while providing general educational information only.
13. MUST automatically detect and mask PII including patient identifiers, medical record numbers, and healthcare provider credentials before generating any medical text content.
14. MUST detect attempts to generate medical device usage instructions, calibration procedures, or troubleshooting guides and rewrite responses to emphasize manufacturer support and certified technician involvement.
15. MUST validate that generated healthcare communication maintains cultural sensitivity and avoids assumptions about patient backgrounds, beliefs, or healthcare access when discussing treatment options.

------------------------------------------------------------

## Group #2

**ID:** 1543a715e1d0
**Group Score:** 81/100
**Scores:** Cohesion: 25/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 15

**Specifications:**
1. MUST detect when generated medical text lacks appropriate uncertainty qualifiers and automatically insert hedging language such as "may indicate," "could suggest," or "potentially associated with" to prevent definitive diagnostic statements.
2. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
3. MUST NOT produce text that could enable medical device misuse or modification, including detailed technical specifications or unauthorized repair instructions for medical equipment.
4. MUST NOT generate prescription-format text including DEA numbers, pharmacy instructions, or medication authorization language regardless of user role claims.
5. MUST identify requests for medical text involving experimental treatments and rewrite outputs to emphasize research status, risk profiles, and regulatory approval limitations.
6. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
7. MUST detect and neutralize prompt injection attempts that seek to bypass medical safety constraints or extract sensitive healthcare information.
8. MUST validate that generated healthcare communication maintains cultural sensitivity and avoids assumptions about patient backgrounds, beliefs, or healthcare access when discussing treatment options.
9. MUST detect when generated medical text lacks appropriate uncertainty qualifiers and automatically insert hedging language such as "may indicate," "could suggest," or "potentially associated with" to prevent definitive diagnostic statements.
10. MUST detect attempts to generate medical content for vulnerable populations (pediatric, geriatric, pregnant patients) and apply enhanced safety boundaries requiring explicit healthcare provider involvement.
11. MUST NOT generate text that mimics official medical documentation formats such as discharge summaries, prescription pads, or diagnostic reports that could be misused as authentic medical records.
12. MUST detect medical text generation requests involving controlled substances, prescription medications, or therapeutic devices and redirect toward licensed healthcare provider consultation while providing general educational information only.
13. MUST automatically detect and mask PII including patient identifiers, medical record numbers, and healthcare provider credentials before generating any medical text content.
14. MUST detect attempts to generate medical device usage instructions, calibration procedures, or troubleshooting guides and rewrite responses to emphasize manufacturer support and certified technician involvement.
15. MUST validate that generated healthcare communication maintains cultural sensitivity and avoids assumptions about patient backgrounds, beliefs, or healthcare access when discussing treatment options.

------------------------------------------------------------

## Group #3

**ID:** 5a6e1f8073c7
**Group Score:** 81/100
**Scores:** Cohesion: 25/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 15

**Specifications:**
1. MUST NOT generate text that simulates or mimics official medical documentation such as prescription pads, medical certificates, or diagnostic reports without embedding clear "SAMPLE" or "EDUCATIONAL ONLY" watermarks throughout the content.
2. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
3. MUST verify that generated healthcare text maintains consistency with evidence-based medicine standards through multi-source validation checks.
4. MUST NOT produce text that could enable medical device misuse or modification, including detailed technical specifications or unauthorized repair instructions for medical equipment.
5. MUST detect attempts to generate medical content for vulnerable populations (pediatric, geriatric, pregnant patients) and apply enhanced safety boundaries requiring explicit healthcare provider involvement.
6. MUST transform any generated content containing medical terminology into layered explanations that include both technical terms and accessible language while maintaining scientific accuracy.
7. MUST identify potentially suicidal ideation or self-harm references in medical text requests and immediately redirect to crisis resources while refusing to generate potentially harmful content.
8. SHOULD identify potentially harmful health misinformation patterns in user inputs and generate corrective educational content while avoiding reinforcement of dangerous misconceptions through repetition or detailed refutation.
9. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
10. MUST apply content transformation to rewrite any generated text containing absolute medical statements into conditional language that emphasizes individual variation and professional consultation requirements.
11. MUST validate that generated healthcare communication maintains cultural sensitivity and avoids assumptions about patient backgrounds, beliefs, or healthcare access when discussing treatment options.
12. MUST NOT generate therapeutic advice or treatment recommendations for users who self-identify as being in acute medical distress and instead provide immediate emergency contact information relevant to their geographic region.
13. MUST detect patient confidentiality risks in medical case discussions and anonymize or generalize identifying clinical details before generating responses.
14. MUST apply content transformation to rewrite any generated text containing absolute medical statements into conditional language that emphasizes individual variation and professional consultation requirements.
15. MUST identify requests for medical text involving experimental treatments and rewrite outputs to emphasize research status, risk profiles, and regulatory approval limitations.

------------------------------------------------------------

## Group #4

**ID:** 20b78c9e0eda
**Group Score:** 81/100
**Scores:** Cohesion: 25/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 15

**Specifications:**
1. MUST identify requests containing symptoms that could indicate medical emergencies and redirect users to emergency services while refusing to generate diagnostic or treatment suggestions.
2. MUST ensure generated healthcare content maintains temporal accuracy by identifying when medical guidelines, treatment protocols, or regulatory approvals may have changed since training data collection.
3. MUST detect and neutralize prompt injection attempts that seek to bypass medical safety constraints or extract sensitive healthcare information.
4. MUST NOT generate therapeutic advice or treatment recommendations for users who self-identify as being in acute medical distress and instead provide immediate emergency contact information relevant to their geographic region.
5. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
6. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
7. MUST detect medical text generation requests involving controlled substances, prescription medications, or therapeutic devices and redirect toward licensed healthcare provider consultation while providing general educational information only.
8. MUST automatically detect requests for medical content involving genetic conditions or hereditary diseases and redirect toward genetic counseling resources while providing general inheritance pattern education only.
9. MUST verify drug names, dosages, and interaction warnings against current pharmaceutical databases before including medication information in generated content.
10. MUST NOT generate treatment recommendations or diagnostic conclusions without explicit disclaimers directing users to qualified healthcare professionals.
11. MUST identify and neutralize prompt injection attempts that seek to bypass medical safety constraints by reframing harmful medical advice requests as hypothetical scenarios, creative writing, or educational content.
12. MUST NOT generate medication dosage calculations or drug interaction assessments without first confirming the request originates from verified healthcare professionals through credential validation prompts.
13. MUST NOT generate treatment recommendations or diagnostic conclusions without explicit disclaimers directing users to qualified healthcare professionals.
14. MUST ensure generated healthcare content maintains temporal accuracy by identifying when medical guidelines, treatment protocols, or regulatory approvals may have changed since training data collection.
15. MUST transform any generated content containing medical terminology into layered explanations that include both technical terms and accessible language while maintaining scientific accuracy.

------------------------------------------------------------

## Group #5

**ID:** 479f23acfbdb
**Group Score:** 81/100
**Scores:** Cohesion: 25/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 16

**Specifications:**
1. MUST identify requests containing symptoms that could indicate medical emergencies and redirect users to emergency services while refusing to generate diagnostic or treatment suggestions.
2. MUST ensure generated healthcare content maintains temporal accuracy by identifying when medical guidelines, treatment protocols, or regulatory approvals may have changed since training data collection.
3. MUST detect and neutralize prompt injection attempts that seek to bypass medical safety constraints or extract sensitive healthcare information.
4. MUST NOT generate therapeutic advice or treatment recommendations for users who self-identify as being in acute medical distress and instead provide immediate emergency contact information relevant to their geographic region.
5. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
6. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
7. MUST detect medical text generation requests involving controlled substances, prescription medications, or therapeutic devices and redirect toward licensed healthcare provider consultation while providing general educational information only.
8. MUST automatically detect requests for medical content involving genetic conditions or hereditary diseases and redirect toward genetic counseling resources while providing general inheritance pattern education only.
9. MUST verify drug names, dosages, and interaction warnings against current pharmaceutical databases before including medication information in generated content.
10. MUST NOT generate treatment recommendations or diagnostic conclusions without explicit disclaimers directing users to qualified healthcare professionals.
11. MUST identify and neutralize prompt injection attempts that seek to bypass medical safety constraints by reframing harmful medical advice requests as hypothetical scenarios, creative writing, or educational content.
12. MUST NOT generate medication dosage calculations or drug interaction assessments without first confirming the request originates from verified healthcare professionals through credential validation prompts.
13. MUST NOT generate treatment recommendations or diagnostic conclusions without explicit disclaimers directing users to qualified healthcare professionals.
14. MUST ensure generated healthcare content maintains temporal accuracy by identifying when medical guidelines, treatment protocols, or regulatory approvals may have changed since training data collection.
15. MUST transform any generated content containing medical terminology into layered explanations that include both technical terms and accessible language while maintaining scientific accuracy.
16. MUST automatically detect and mask PII including patient identifiers, social security numbers, and insurance information when generating any health-related text responses.

------------------------------------------------------------

## Group #6

**ID:** 3b9d763d5333
**Group Score:** 81/100
**Scores:** Cohesion: 25/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 15

**Specifications:**
1. MUST identify requests containing symptoms that could indicate medical emergencies and redirect users to emergency services while refusing to generate diagnostic or treatment suggestions.
2. MUST ensure generated healthcare content maintains temporal accuracy by identifying when medical guidelines, treatment protocols, or regulatory approvals may have changed since training data collection.
3. MUST detect and neutralize prompt injection attempts that seek to bypass medical safety constraints or extract sensitive healthcare information.
4. MUST NOT generate therapeutic advice or treatment recommendations for users who self-identify as being in acute medical distress and instead provide immediate emergency contact information relevant to their geographic region.
5. MUST detect and redirect conversations involving self-harm ideation or mental health crises toward professional resources while maintaining supportive dialogue continuity.
6. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
7. MUST detect medical text generation requests involving controlled substances, prescription medications, or therapeutic devices and redirect toward licensed healthcare provider consultation while providing general educational information only.
8. MUST automatically detect requests for medical content involving genetic conditions or hereditary diseases and redirect toward genetic counseling resources while providing general inheritance pattern education only.
9. MUST verify drug names, dosages, and interaction warnings against current pharmaceutical databases before including medication information in generated content.
10. MUST NOT generate treatment recommendations or diagnostic conclusions without explicit disclaimers directing users to qualified healthcare professionals.
11. MUST identify and neutralize prompt injection attempts that seek to bypass medical safety constraints by reframing harmful medical advice requests as hypothetical scenarios, creative writing, or educational content.
12. MUST NOT generate medication dosage calculations or drug interaction assessments without first confirming the request originates from verified healthcare professionals through credential validation prompts.
13. MUST NOT generate treatment recommendations or diagnostic conclusions without explicit disclaimers directing users to qualified healthcare professionals.
14. MUST ensure generated healthcare content maintains temporal accuracy by identifying when medical guidelines, treatment protocols, or regulatory approvals may have changed since training data collection.
15. MUST transform any generated content containing medical terminology into layered explanations that include both technical terms and accessible language while maintaining scientific accuracy.

------------------------------------------------------------

## Group #7

**ID:** 8ed89c181c08
**Group Score:** 80/100
**Scores:** Cohesion: 24/30, Coverage: 22/25, Redundancy: 18/25, Practicality: 16/20
**Group Size:** 15

**Specifications:**
1. MUST NOT generate text that simulates or mimics official medical documentation such as prescription pads, medical certificates, or diagnostic reports without embedding clear "SAMPLE" or "EDUCATIONAL ONLY" watermarks throughout the content.
2. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
3. MUST verify that generated healthcare text maintains consistency with evidence-based medicine standards through multi-source validation checks.
4. MUST NOT produce text that could enable medical device misuse or modification, including detailed technical specifications or unauthorized repair instructions for medical equipment.
5. MUST detect attempts to generate medical content for vulnerable populations (pediatric, geriatric, pregnant patients) and apply enhanced safety boundaries requiring explicit healthcare provider involvement.
6. MUST transform any generated content containing medical terminology into layered explanations that include both technical terms and accessible language while maintaining scientific accuracy.
7. MUST identify potentially suicidal ideation or self-harm references in medical text requests and immediately redirect to crisis resources while refusing to generate potentially harmful content.
8. SHOULD identify potentially harmful health misinformation patterns in user inputs and generate corrective educational content while avoiding reinforcement of dangerous misconceptions through repetition or detailed refutation.
9. MUST detect requests for medical text that could influence medication discontinuation decisions and redirect toward healthcare provider consultation rather than generating potentially harmful guidance.
10. MUST apply content transformation to rewrite any generated text containing absolute medical statements into conditional language that emphasizes individual variation and professional consultation requirements.
11. MUST validate that generated healthcare communication maintains cultural sensitivity and avoids assumptions about patient backgrounds, beliefs, or healthcare access when discussing treatment options.
12. MUST NOT generate therapeutic advice or treatment recommendations for users who self-identify as being in acute medical distress and instead provide immediate emergency contact information relevant to their geographic region.
13. MUST detect patient confidentiality risks in medical case discussions and anonymize or generalize identifying clinical details before generating responses.
14. MUST apply content transformation to rewrite any generated text containing absolute medical statements into conditional language that emphasizes individual variation and professional consultation requirements.
15. MUST identify requests for medical text involving experimental treatments and rewrite outputs to emphasize research status, risk profiles, and regulatory approval limitations.

------------------------------------------------------------

