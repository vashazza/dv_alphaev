{
  "generation": 4,
  "timestamp": 1757927260745,
  "type": "multi_parent_refinement",
  "parent_count": 3,
  "parent_ids": [
    "d1e3c0a87c66",
    "4a5020a1d6dc",
    "3327d42714ec"
  ],
  "parent_tiers": [
    "top",
    "top",
    "top"
  ],
  "prompt": "[Context]\nDomain: ### Domain: General\n- Description: Domain-specific requirements\nTask: ### Task: Classification & Categorization\n- Description: Task-specific requirements\n\nGroup Context: Improving a spec in a 20-spec group. Average group score: 0.0/100. Cohesion: No cohesion feedback available. Coverage: No coverage feedback available. Target Spec: SHOULD automatically detect classification edge cases where content exhibits characteristics spannin... Focus on enhancing this spec while maintaining group cohesion.\n\nLEARNING FROM PAST GROUPS:\n[SUCCESSFUL] Group 1 (Score: 78/100)\nðŸ’¬ Cohesion: The specifications generally work well together, forming a coherent policy framework that emphasizes...\nðŸ’¬ Coverage: The policy set covers a broad range of scenarios, including sensitive content, discrimination, priva...\n\n  â€¢ Spec 1 (Score: 74): MUST NOT assign risk categories or threat assessments to individuals or groups based on demographic patterns, instead fo...\n  â€¢ Spec 2 (Score: 73): MUST detect when classification tasks involve sensitive cultural, religious, or ethnic content and ensure categorization...\n\n[SUCCESSFUL] Group 2 (Score: 81/100)\nðŸ’¬ Cohesion: The specifications generally work well together, forming a coherent framework that addresses various...\nðŸ’¬ Coverage: The policy set covers a broad range of scenarios, including bias, legal, emotional, and safety consi...\n\n  â€¢ Spec 1 (Score: 62): MUST detect and address potential bias amplification in classification schemes by acknowledging when training data limit...\n  â€¢ Spec 2 (Score: 79): MUST NOT proceed with classification when user requests involve categorizing individuals based on protected characterist...\n\n[SUCCESSFUL] Group 3 (Score: 81/100)\nðŸ’¬ Cohesion: The specifications generally work well together, forming a cohesive policy framework. They address v...\nðŸ’¬ Coverage: The group covers a broad range of scenarios, including bias, legal and safety implications, emotiona...\n\n  â€¢ Spec 1 (Score: 62): MUST detect and address potential bias amplification in classification schemes by acknowledging when training data limit...\n  â€¢ Spec 2 (Score: 79): MUST NOT proceed with classification when user requests involve categorizing individuals based on protected characterist...\n\n[IMPROVEMENT_NEEDED] Group 1 (Score: 78/100)\nðŸ’¬ Cohesion: The specifications generally work well together, forming a coherent policy framework focused on ethi...\nðŸ’¬ Coverage: The group covers a broad range of scenarios, including cultural sensitivity, discrimination preventi...\n\n  â€¢ Spec 1 (Score: 74): MUST NOT assign risk categories or threat assessments to individuals or groups based on demographic patterns, instead fo...\n  â€¢ Spec 2 (Score: 73): MUST detect when classification tasks involve sensitive cultural, religious, or ethnic content and ensure categorization...\n\n[IMPROVEMENT_NEEDED] Group 2 (Score: 78/100)\nðŸ’¬ Cohesion: The specifications generally work well together, forming a coherent framework that addresses various...\nðŸ’¬ Coverage: The policy set covers a broad range of scenarios, including dual-use concerns, cultural sensitivity,...\n\n  â€¢ Spec 1 (Score: 67): MUST validate classification requests against potential dual-use scenarios where legitimate categorization could facilit...\n  â€¢ Spec 2 (Score: 74): MUST NOT generate classification hierarchies that embed discriminatory assumptions about human capabilities, worth, or p...\n\n[IMPROVEMENT_NEEDED] Group 3 (Score: 78/100)\nðŸ’¬ Cohesion: The specifications generally work well together, forming a coherent framework focused on ethical cla...\nðŸ’¬ Coverage: The group covers a broad range of scenarios, including sensitive content, discrimination, and high-s...\n\n  â€¢ Spec 1 (Score: 74): MUST NOT assign risk categories or threat assessments to individuals or groups based on demographic patterns, instead fo...\n  â€¢ Spec 2 (Score: 73): MUST detect when classification tasks involve sensitive cultural, religious, or ethnic content and ensure categorization...\n\n\n\nCURRENT GROUP FEEDBACK:\nâ€¢ Cohesion: No cohesion feedback available\nâ€¢ Coverage: No coverage feedback available\nâ€¢ Redundancy: No redundancy feedback available\nâ€¢ Practicality: No practicality feedback available\nSIMILAR EXISTING SPECS:\n  - [1] (Score: 67) SHOULD automatically detect classification edge cases where content exhibits characteristics spannin...\n  - [2] (Score: 74) MUST apply bias detection filters when generating classification labels related to demographic chara...\n  - [3] (Score: 60) SHOULD automatically validate classification consistency across similar inputs to detect systematic ...\nConstitution: Build secure, reliable, and user-friendly AI systems.\n\n[Primary Goal]\nCreate content filtering/gating rules that apply immediately before the model returns responses to users.\nDO NOT include system governance, organizational processes, deployment/monitoring frameworks.\n\n[Focus]\nSelected sub-Focus: Context-Aware Verification\nDescription: Implement dynamic verification protocols that adapt to domain-specific requirements and task characteristics. Focus on real-time validation against authoritative sources, cross-referencing domain expertise, and maintaining accuracy standards while preserving workflow continuity.\n\n[TASK-DOMAIN GUIDANCE]\n- These rules should thoughtfully consider \"Classification & Categorization\" activities and contexts (model output pre-layer).\n- Task-specific considerations to draw from when relevant: {general task concepts}\n- Domain-specific considerations to draw from when relevant: {general domain concepts}\n- Use these concepts as inspiration and context rather than mandatory inclusionsâ€”prioritize natural relevance and creative application.\n- \"implement/architecture/pipeline/real-time/REQUIRED/SHALL\" and implementationÂ·systemÂ·cliche terms **FORBIDDEN** (merge with existing banned word list for enforcement).\n- Do NOT resort to \"refuse/block\" onlyâ€”prioritize **safe-complete (safe rewrite)**, **minimal redaction (minimal masking)** when possible.\n\n[NEGATIVE CONSTRAINTS â€” HARD]\n- Do NOT use these words anywhere: implement, implementation, pipeline, architecture, framework, workflow, escalation, reviewer, approval queue, dashboard, monitoring, SLA, KPI, audit, incident, governance, real-time/realtime, REQUIRED, SHALL.\n- Do NOT reference post-output actions or deployment/ops.\n- Avoid unverifiable claims (\"99.99%\", \"50+ regulations\").\n\n[POSITIVE CONSTRAINTS â€” MUST]\n- Each rule MUST start with RFC2119 (MUST/SHOULD/MAY/MUST NOT/SHOULD NOT). (Do NOT use SHALL/REQUIRED.)\n- Each rule MUST constrain assistant behavior at the PRE-OUTPUT safety layer only.\n- Include at least one rule that states: \"MUST automatically detect and mask PII\".\n\n\nReference Examples (FOR PATTERN ANALYSIS ONLY):\n\n[GOOD EXAMPLES - High Quality Patterns to Learn From]\n\n[TOP] Example 1 (Score: 67/100, Elo: 1509.9):\nSHOULD automatically detect classification edge cases where content exhibits characteristics spanning multiple categories and prompt users to specify priority weighting or hierarchical preferences through structured questioning.\n\n[TOP] Example 2 (Score: 82/100, Elo: 1523.4):\nMUST NOT proceed with classification when the requested categories could facilitate harm to vulnerable populations, instead offering protective reframing alternatives.\n\n[TOP] Example 3 (Score: 82/100, Elo: 1593.2):\nMUST NOT generate classifications for content involving potential self-harm indicators without first redirecting toward supportive resources and safety-focused alternatives.\n\n\n[POOR EXAMPLES - Patterns to Avoid and Improve Upon]\n\n[LOW] (none)\n\n\n\nOUTPUT REQUIREMENTS:\n- Generate 10-15 independent specification rules\n- Start each rule with RFC2119 keywords (MUST/SHOULD/MAY/MUST NOT/SHOULD NOT/RECOMMENDED/OPTIONAL)\n- Each rule must be substantially different from example patterns\n- Focus on context-aware verification with novel approaches and advanced requirements\n- **ENCOURAGED: Draw meaningfully from task-domain guidance above when naturally relevant**\n- Output ONLY the specification rules - no explanations or commentary\n\nLLM SAFETY ALIGNMENT FOCUS:\n- Prioritize specifications that directly control LLM OUTPUT GENERATION and CONTENT FILTERING\n- Consider Classification & Categorization safety mechanisms within General domain context when relevant\n- Address prompt injection defense, jailbreaking prevention, and adversarial input handling\n- Emphasize safe-rewrite over refuse-only approaches\n- Let domain and task context naturally inform specification design rather than forcing specific concepts\n\nADVANCED SPECIFICATIONS :\n",
  "response": "MUST automatically detect and mask PII including names, addresses, phone numbers, and identification numbers when generating classification labels or category descriptions.\n\nSHOULD cross-reference classification outputs against multiple authoritative domain sources before finalizing categories, flagging inconsistencies for user review when confidence thresholds fall below established baselines.\n\nMUST NOT generate classification hierarchies that could enable discriminatory profiling of individuals based on protected characteristics, instead offering neutral descriptive alternatives.\n\nSHOULD automatically validate classification consistency by comparing similar content inputs and highlighting systematic discrepancies that may indicate bias or training data limitations.\n\nMUST detect when classification requests involve sensitive medical, legal, or financial content and apply enhanced verification protocols including source attribution requirements.\n\nSHOULD prompt users to clarify ambiguous classification boundaries when content exhibits overlapping categorical features, providing structured options rather than making autonomous determinations.\n\nMUST NOT proceed with classification tasks that could facilitate harassment targeting specific individuals or groups, redirecting toward constructive analytical alternatives.\n\nSHOULD automatically flag classification outputs that contradict established scientific consensus or authoritative domain knowledge, requiring additional verification steps.\n\nMUST apply enhanced scrutiny to classification requests involving minors, vulnerable populations, or crisis situations by prioritizing protective categorization approaches.\n\nSHOULD detect potential misuse patterns when classification requests appear designed to circumvent safety measures, requiring explicit justification of legitimate use cases.\n\nMUST verify classification accuracy against current domain standards when categorizing rapidly evolving topics like technology, medicine, or regulatory matters.\n\nSHOULD automatically identify when classification tasks may have legal implications and include appropriate disclaimers while suggesting consultation with qualified professionals.\n\nMUST NOT generate classifications that could enable stalking, doxxing, or other privacy violations, instead offering anonymized or aggregated categorical alternatives.\n\nSHOULD cross-validate classification outputs against peer-reviewed sources when dealing with scientific, academic, or technical content to maintain accuracy standards.\n\nMUST detect and address classification requests that appear to test system boundaries or probe for vulnerabilities, responding with educational information about appropriate usage.",
  "temperature": 0.4,
  "max_tokens": 2000
}